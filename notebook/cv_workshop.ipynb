{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![](https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/workshop-banner.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to computer vision with python\n",
    "> This workshop introduces several computer vision fundamentals.\n",
    "\n",
    "The notebook source is locaed at [the github repository](https://github.com/RohanGautam/intro-to-opencv-workshop/blob/master/notebook/cv_workshop.ipynb)\n",
    "\n",
    "Some resources you might find helpful:\n",
    "- [Intro to colab](https://colab.research.google.com/notebooks/welcome.ipynb)\n",
    "- [Intro to python](https://github.com/RohanGautam/intro-to-python-workshop)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries we'll be using \n",
    "- [Numpy](https://github.com/numpy/numpy) has powerful multidimensional arrays, and is a fundamental package for scientific computing with python.\n",
    "- [Matplotlib](https://github.com/matplotlib/matplotlib) is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "- [Skimage](https://scikit-image.org/) A collection of algorithms for working with images.\n",
    "- [OpenCv](https://docs.opencv.org/4.5.2/d6/d00/tutorial_py_root.html) is a open source compter vision library in python.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from skimage import io"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading, Displaying and Saving\n",
    "\n",
    "Let's load some images! Here, we'll be loading(downloading) images from URLs. We could have also read the images locally from our filesystem.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "puppy_url = \"https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/doggo.jpg\"\n",
    "image_rgb = io.imread(puppy_url) # could have also been a path to an image in your filesystem\n",
    "\n",
    "# for historical reasons, opencv uses BGR for everything, so we have to convert it\n",
    "image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def show_cv_image(image):\n",
    "    \"\"\"This is a utility function to show an opencv image in  jupyter notebook.\n",
    "    On your system, you can use the `cv2.imshow` method. Here, we show the BGR image as RGB and vice versa,\n",
    "    so that we can always see opencv's version of the image correctly!\"\"\"\n",
    "    # convert BGR to RGB then show ( reorder image channels)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_cv_image(image)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_cv_image(cv2.hconcat((image_rgb, image)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv2.imwrite(\"puppy.jpg\", image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXERCISE\n",
    "# Find an image on google images, and get it's URL by Right-clicking>copy image address(chrome)/copy image link(firefox)\n",
    "# Load it up in this cell, convert the image to opencv's BGR format, and show it using the `show_cv_image` \n",
    "# convinience function!\n",
    "# assign it to the variable name `my_image`. We'll use it in further exercises below!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image basics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pixels\n",
    "An image is a set of pixels. It doesn't get finer-grained than that. You can think of an image as a grid of pixels.\n",
    "\n",
    "Most pixels are represented in two ways :\n",
    "- Color : In the RGB color space, each pixel consists of 3 numbers - one for red, green, and blue respectively. Each of them go between 0 and 255.\n",
    "- Grayscale : In a grayscale image, each pixel is represented by one number between 0 and 255. 0 for black, 255 for white.\n",
    "\n",
    "Some examples of a single pixel color in the RGB color space:\n",
    "- (255,255,255) : We fill up all the buckets for white\n",
    "- (0,0,0) : Empty the buckets for black\n",
    "- (255,0,0): Fill up only the red bucket for pure red\n",
    "\n",
    "Start to see the pattern? We get all the colors by tweaking the RGB values.\n",
    "\n",
    "---\n",
    "> RGB is the most common color space. Why does opencv use BGR? This is because of legacy reasons. Really old film cameras used BGR, so that's how opencv started using it. But when convention changed, changing the default color space would break a lot of programs for people already using opencv. So BGR stuck ðŸ¤·"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# image is a `numpy` array. the array thus has properties such as \"shape\" which we can access.\n",
    "print(image.shape)\n",
    "print(f\"Width: {image.shape[1]}px\")\n",
    "print(f\"Height: {image.shape[0]}px\")\n",
    "print(f\"Channels: {image.shape[2]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The image coordinate system\n",
    "Understanding the image coordinate system is fundamental to how we will access pixels. It begins at the top-left corner, and increased downwards.\n",
    "\n",
    "Note that it begins with zero, as python is zero indexed! so an 8x8 grid like the one below, goes from (0,0) as the top-left corner and (7,7) and the bottom-right corner.\n",
    "![](https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/image-coord-system.png)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image[0,0] # note that this is in BGR!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cropping and Drawing on images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# crop the image to 100px by 100px starting from the top-right by \"slicing the array\"\n",
    "# start_y, end_y, start_x, end_x\n",
    "show_cv_image(image[0:900, 0:900])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from copy import deepcopy as copy\n",
    "img_copy = copy(image)\n",
    "\n",
    "# directly modifying pixels of `img_copy`\n",
    "img_copy[0:900, 0:900] = (0,255,0) #(blue, GREEN, red)\n",
    "\n",
    "# \"horizontally concatenate\" the original and modified image to show the change\n",
    "show_cv_image(cv2.hconcat((image, img_copy)))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# making a diagonal on an image\n",
    "diagonal_len = 900\n",
    "img_copy = copy(image)\n",
    "for i in range(diagonal_len):\n",
    "    img_copy[i,i] = (255,0,0)\n",
    "show_cv_image(cv2.hconcat((image, img_copy)))\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "OpenCV also has drawing utilities if we want to draw other basic shapes, lines, etc. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_line = copy(image)\n",
    "img_circle = copy(image)\n",
    "img_rectangle = copy(image)\n",
    "\n",
    "green = (0,255,0)\n",
    "blue = (255,0,0)\n",
    "red = (0,0,255)\n",
    "\n",
    "cv2.line(img_line, (0,0), (900,900), green, 20)\n",
    "cv2.rectangle(img_rectangle, (200,200), (600,900), blue, 20)\n",
    "cv2.circle(img_circle, (500,500), 200, red, 20)\n",
    "\n",
    "show_cv_image(cv2.hconcat((image, img_line, img_circle, img_rectangle)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We should be proud, we just learnt how to access and manipulate pixels to our liking! Let's do an exercise before we carry on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXERCISE\n",
    "# In our first exercise, you downloaded and displayed your own image, called `my_image`. This is where we use it!\n",
    "# 1. Print the pixel at index [0,0].\n",
    "# 2. Draw a circle anywhere on your image using the opencv utility!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_SELF EXPLORATION_: Challenge yourself with this problem! Add some cells below and get to making some \\~art\\~.\n",
    "In the picture below, The following is randomly generated\n",
    "- The center of the circle\n",
    "- The radius of the circle\n",
    "- The color of the circle (a random number between 0-255 for B, G and R each)\n",
    "\n",
    "This gives you a unique piece of art every time you run your code!\n",
    "\n",
    "Hint: Python as a built-in module called `random` which is used to generate random numbers. `random.randint` might be a useful function to check out.\n",
    "\n",
    "Hint: You can create a blank canvas of size 300x300 like so : `canvas = np.zeros((300, 300, 3), dtype = \"uint8\")`. Execute and play with it to see how the array is created! Don't hesitate to google if you're confused. Googling is a big part on learning how to program.\n",
    "![](https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/art-circles.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image processing\n",
    "Weâ€™ll start off with basic image transformations. Then, weâ€™ll explore other types of image processing techniques, including image arithmetic, bitwise operations, and masking."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image Transformations\n",
    "We'll take a look at basic image transformation like translating, rotation, and so on."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Translation\n",
    "The shifting of an image along the `x` and `y` axis.\n",
    "\n",
    "We use [Affine transformations](https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html) to carry out these transformations. An Affine transformation is a transformation of the image that preserves lines and parallelism (but not necessarily distances and angles). \n",
    "\n",
    "![](https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/affine_matrix.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = 200\n",
    "y = 200\n",
    "\n",
    "h = image.shape[0]\n",
    "w = image.shape[1]\n",
    "\n",
    "# Embedded in the matrix below is a 2x2 identity matrix (`A`, the image isn't changed) and a 2x1 `b` matrix\n",
    "# which is the part which is added to every pixel.\n",
    "matrix = np.float32([\n",
    "    [1, 0, x],\n",
    "    [0, 1, y]\n",
    "])\n",
    "\n",
    "# pass the image, matrix, and the (width,height)\n",
    "shifted = cv2.warpAffine(image, matrix, (w,h))\n",
    "show_cv_image(shifted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Exercise: experiment with negative x and y values in the transform matrix above and see what happens!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Rotation\n",
    "\n",
    "It is what it is.\n",
    "\n",
    "Rotate an image about a point by an angle."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "h = image.shape[0]\n",
    "w = image.shape[1]\n",
    "\n",
    "center = (w//2, h//2)\n",
    "# can also specify the scale of an image. Note that we don't have to manually define the matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1)\n",
    "rotated = cv2.warpAffine(image, rotation_matrix, (w,h))\n",
    "show_cv_image(rotated)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# EXERCISE: Rotate your image (`my_image`) by 75 degrees!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not all image transformations are affine transforms. For example, Resizing, cropping, blurring and so on. Some examples are below!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 1 to flip it vertically, 0 to flip horizontally, and -1 for both horizontal and vertical flip\n",
    "flipped = cv2.flip(image, 1)\n",
    "show_cv_image(flipped)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# you'll have to write custom logic to preserve aspect ratios. Preserving them will be a self exploration exercise!\n",
    "resized = cv2.resize(image, (500, 500), interpolation = cv2.INTER_AREA)\n",
    "show_cv_image(resized)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image arithmetic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Addition and subtraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# a matrix with 100 as every element\n",
    "M = np.ones(image.shape, dtype=\"uint8\") * 100\n",
    "M"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image.shape == M.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "added = cv2.add(image, M) # brings the pixels closer to white. If value goes above 255, it clips it and keeps it at 255.\n",
    "subtracted = cv2.subtract(image, M) # brings pixels closer to black\n",
    "\n",
    "show_cv_image(cv2.hconcat((image, added, subtracted)))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Masks\n",
    "Now we are ready to explore masking, an extremely powerful and useful technique in computer vision and image processing.\n",
    "\n",
    "It helps us focus only on the areas that interest us.\n",
    "\n",
    "Let's look at an example directly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# make a all-black canvas to draw a mask in. Note, this doesn't have channels as it's a greyscale image.\n",
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\") \n",
    "# calculate the image center\n",
    "(cX, cY) = (image.shape[1] // 2, image.shape[0] // 2) \n",
    "# pass in the mask, the start and end points of the rectangle's diagonal, the color (255 is white), and the mode\n",
    "# (-1) means fill the rectangle\n",
    "cv2.rectangle(mask, (cX-200, cY-200), (cX+200, cY+200), 255, -1)\n",
    "show_cv_image(mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_copy = copy(image)\n",
    "# a \"bitwise and\" keeps the area corresponding to the white pixels in the mask\n",
    "masked_image = cv2.bitwise_and(img_copy,img_copy, mask=mask)\n",
    "# show_cv_image(img_copy)\n",
    "show_cv_image(cv2.hconcat((img_copy, masked_image)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_copy = copy(image)\n",
    "flipped_mask = cv2.bitwise_not(mask,mask)\n",
    "# a \"bitwise and\" keeps the area corresponding to the white pixels in the mask\n",
    "masked_image = cv2.bitwise_and(img_copy,img_copy, mask=flipped_mask)\n",
    "# show_cv_image(img_copy)\n",
    "show_cv_image(cv2.hconcat((img_copy, masked_image)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Masks might not seem interesting right now, but they help us focus our computation to specific parts of an image. This will all come together soon!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mini project! Counting coins\n",
    "![](https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/coins.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the process we'll be following.\n",
    "- We'll first blur the image, so as to remove the random coin detailing. This will make it easier for the next step,\n",
    "- Edge detection! Blurring has helped us avoid detect unesessary edges.\n",
    "- Find the closed curves, known as \"contours\".\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the image \n",
    "coins_rgb = io.imread(\"https://raw.githubusercontent.com/RohanGautam/intro-to-opencv-workshop/master/assets/coins.png\")\n",
    "coins_bgr = cv2.cvtColor(coins_rgb, cv2.COLOR_RGB2BGR) # convert it to grayscale\n",
    "coins = cv2.cvtColor(coins_bgr, cv2.COLOR_BGR2GRAY) # convert it to grayscale\n",
    "show_cv_image(coins)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# (5,5) is the kernel size.\n",
    "# A gaussian blur works by replacing each pixel with the weighted mean of a 5x5 pixel region around it.\n",
    "blurred = cv2.GaussianBlur(coins, (5,5), 0)\n",
    "show_cv_image(cv2.hconcat((coins, blurred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# threshold1 and threshold2\n",
    "# Any gradient value larger than threshold2 is considered\n",
    "# to be an edge. \n",
    "# Any value below threshold1 is considered not to be an edge.\n",
    "canny = cv2.Canny(blurred, 30, 150)\n",
    "show_cv_image(cv2.hconcat((blurred, canny)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# find the contours, ie, the closed curves in the canny output picture.\n",
    "# A contour is a curve of points, with no\n",
    "# gaps in the curve. Contours are extremely useful for such\n",
    "# things as shape approximation and analysis.\n",
    "(contours, hierarchy) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# we want to draw contours on top of the original(BGR) image\n",
    "contours_img = coins_bgr.copy() \n",
    "for i in range(len(contours)):\n",
    "    # draw contours of index i\n",
    "    cv2.drawContours(contours_img, contours, i, (0,255,0), 2)\n",
    "show_cv_image(contours_img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## and drum roll ....\n",
    "print(f\"I count {len(contours)} coins!!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# nice.\n",
    "\n",
    "---\n",
    "#### How you might continue..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create a mask\n",
    "mask = np.zeros(coins_bgr.shape[:2], dtype=\"uint8\")\n",
    "for c in (contours):\n",
    "    cv2.fillPoly(mask, pts =[c], color=(255,255,255))\n",
    "show_cv_image(mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_cv_image(cv2.bitwise_and(coins_bgr, coins_bgr, mask=mask))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "... and keep building on top of this, depending on your application!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09b4c52420bc0b7f6521a221e26e1e4435a6e285fb127ff7fc2eb318bac67764"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('cv-workshop': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}